---
layout:     post                    # 使用的布局（不需要改）
title:      rq         # 标题 
subtitle:   探索 rq  #副标题
date:       2019-05-23              # 时间
author:     ZYT                     # 作者
header-img: img/rq.jpg     #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:
    - rq                               #标签
    - 基础架构
---

# 一、rq 使用

```
# test_func.py
def test_count(num):
    return num + 1
```

```
# scheduling.py
from redis import Redis
from rq import Queue

queue = Queue(connection=Redis())

## 添加任务
from test_func import test_count

job = queue.enqueue(test_count, 1)
print(job.key)
```

执行 `scheduling.py` 文件

```
$ python scheduling.py
```

**查看 redis 中的存储情况：**

```
redis-cli> keys *
"rq:job:uuid"(type -> hash)
"rq:queues"(type -> list) 其中包含所有的队列名称
"rq:queue:default"(type -> set) 其中包含所有的 Job 名称

redis-cli> smembers "rq:queues"
"rq:queue:default"

redis-cli> lrange "rq:queue:default" 0 -1
"uuid" Job 的 uuid 值

redis-cli> hgetall "rq:job:uuid" 查看 Job 详情
 1) "status"
 2) "queued"
 3) "created_at"
 4) "2019-05-23T03:23:59.805852Z"
 5) "data"
 6) "x\x9ck`\x99\xaa\xcb\x00\x01\x1a=rE\xa9\x85\xa5\xa9\xc5%\xf1\xa5E9z\xc9\xf9\xa5y%\xf1\xe5\xf9E)\xc5\xf1\x89`\xa1)~\xbe\xbe\x8c\xadSj\xa7\x94L\xd1\x03\x00\xe1\x04\x13|"
 7) "origin"
 8) "default"
 9) "description"
10) "request_url.count_words_at_url(333)"
11) "enqueued_at"
12) "2019-05-23T03:23:59.805938Z"
13) "timeout"
14) "180"
```

执行 `rq worker`

```
redis-cli> hgetall "rq:job:uuid" 查看 Job 详情
 1) "status"
 2) "finished"
 3) "created_at"
 4) "2019-05-23T06:13:27.519230Z"
 5) "data"
 6) "x\x9ck`\x99\xaa\xc3\x00\x01\x1a=rE\xa9\x85\xa5\xa9\xc5%\xf1\xa5E9z\xc9\xf9\xa5y%\xf1\xe5\xf9E)\xc5\xf1\x89`\xa1)~\xde\xcc\xadSj\xa7\x94L\xd1\x03\x00\xceK\x13."
 7) "origin"
 8) "default"
 9) "description"
10) "request_url.count_words_at_url(3)"
11) "enqueued_at"
12) "2019-05-23T06:13:27.519320Z"
13) "timeout"
14) "180"
15) "started_at"
16) "2019-05-23T06:13:48.623350Z"
17) "ended_at"
18) "2019-05-23T06:13:48.624388Z"
19) "result"
20) "\x80\x04K\x04."
```

# 二、存在的问题

1. 在任务执行过程中，停止 rq worker，重新启动不会重新消费信息，且错误信息不会写入 redis
